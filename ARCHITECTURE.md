# SAR AI Platform â€” Complete Architecture & File Reference

## Project Overview

**SAR Narrative Generator Platform** is an intelligent Suspicious Activity Report (SAR) generation system designed for financial institutions to streamline compliance reporting. It uses AI-powered analysis, vector-based retrieval (RAG), and role-based access control to create audit-compliant narratives with complete transaction tracking.

---

## ðŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (Streamlit)                          â”‚
â”‚  Dashboard | Create Case | Generate SAR | Audit Trail | Settings â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP (JSON)
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend (Port 8001)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Routes Layer (7 routers)                                 â”‚   â”‚
â”‚  â”‚ â€¢ case_routes       â†’ Create/Retrieve cases             â”‚   â”‚
â”‚  â”‚ â€¢ sar_routes        â†’ Generate/Export SARs              â”‚   â”‚
â”‚  â”‚ â€¢ audit_routes      â†’ Audit trail queries               â”‚   â”‚
â”‚  â”‚ â€¢ auth_routes       â†’ JWT authentication                â”‚   â”‚
â”‚  â”‚ â€¢ risk_routes       â†’ Risk pattern detection            â”‚   â”‚
â”‚  â”‚ â€¢ rag_routes        â†’ RAG index management              â”‚   â”‚
â”‚  â”‚ â€¢ model_routes      â†’ LLM model operations              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Services Layer (11 services)                             â”‚   â”‚
â”‚  â”‚ â€¢ storage           â†’ SQLite persistence                â”‚   â”‚
â”‚  â”‚ â€¢ sar_generator     â†’ Narrative generation              â”‚   â”‚
â”‚  â”‚ â€¢ rag_store         â†’ FAISS vector indexing             â”‚   â”‚
â”‚  â”‚ â€¢ llm               â†’ Model interface (stub/local)      â”‚   â”‚
â”‚  â”‚ â€¢ risk_engine       â†’ Transaction analysis              â”‚   â”‚
â”‚  â”‚ â€¢ audit_logger      â†’ Audit trail management            â”‚   â”‚
â”‚  â”‚ â€¢ rbac_service      â†’ Role-based access                 â”‚   â”‚
â”‚  â”‚ â€¢ exporter          â†’ PDF generation (ReportLab)        â”‚   â”‚
â”‚  â”‚ â€¢ explainability    â†’ Decision reasoning                â”‚   â”‚
â”‚  â”‚ â€¢ task_manager      â†’ Async job handling                â”‚   â”‚
â”‚  â”‚ â€¢ prompt_templates  â†’ LLM prompt engineering            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                â†“                â†“             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ SQLite  â”‚      â”‚ FAISS  â”‚     â”‚ LLM      â”‚   â”‚ Audit   â”‚
   â”‚ Databaseâ”‚      â”‚ Vector â”‚     â”‚ (Stub)   â”‚   â”‚ Logs    â”‚
   â”‚ (4 TBs) â”‚      â”‚ Index  â”‚     â”‚          â”‚   â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Directory Structure & File Descriptions

### Root Level
```
e:\Barclay\sar-ai-platform\
â”œâ”€â”€ backend/                    # FastAPI backend application
â”œâ”€â”€ frontend/                   # Streamlit frontend
â”œâ”€â”€ sample_data/                # JSON test cases for demonstration
â”œâ”€â”€ alembic/                    # Database migration framework
â”œâ”€â”€ .github/                    # GitHub Actions CI/CD
â”œâ”€â”€ docker-compose.yml          # Docker services (Redis, Postgres)
â”œâ”€â”€ README.md                   # Project overview
â”œâ”€â”€ ARCHITECTURE.md            # This file
â”œâ”€â”€ FEATURES.md                # Feature documentation
â””â”€â”€ API_DOCUMENTATION.md       # API endpoint reference
```

---

## ðŸ”§ Backend Directory (`backend/`)

### Main Application Entry
**File:** `backend/app/main.py` (75 lines)
```python
Purpose:    FastAPI application entrypoint
Imports:    7 routers (case, sar, audit, auth, risk, rag, model)
Features:   â€¢ CORS middleware (allows all origins for local demo)
            â€¢ Database auto-initialization on startup
            â€¢ FAISS index auto-load/save lifecycle hooks
            â€¢ Root endpoint returns system status
```

**Execution Flow:**
1. On startup: Ensure SQLite DB exists, execute schema.sql
2. Load FAISS index from disk if available
3. On shutdown: Save FAISS index to disk

---

### `backend/app/routes/` â€” API Endpoints

#### **1. case_routes.py** (38 lines)
```
Endpoints:   POST /cases/create          â€” Create new SAR case
             GET  /cases/{case_id}       â€” Retrieve case details

Logic:       â€¢ Validate payload structure (customer_name, transactions, alerts)
             â€¢ Generate unique case_id (CASE-{8-char-hex})
             â€¢ Save case to SQLite database
             â€¢ Return status + case_id

Example Response:
{
  "status": "created",
  "case_id": "CASE-a1b2c3d4"
}
```

#### **2. sar_routes.py** (55 lines)
```
Endpoints:   POST /sars/generate              â€” Generate SAR narrative
             GET  /sars/export/{sar_id}      â€” Export SAR as PDF
             GET  /sars/versions/{case_id}   â€” List SAR versions
             GET  /sars/versions/compare/{case_id} â€” Compare versions
             GET  /sars/status/{sar_id}      â€” Get SAR status

Logic:       â€¢ case_id â†’ fetch case from storage
             â€¢ Run risk detection on transactions (find suspicious patterns)
             â€¢ Generate explainability (why patterns detected)
             â€¢ Call LLM to write SAR narrative
             â€¢ Save to database with audit trail
             â€¢ Support PDF export via ReportLab

Example Flow:
POST /sars/generate?case_id=CASE-a1b2c3d4
â†“
1. Fetch case + transactions
2. Risk engine analyzes transactions ($50k+ transfers, rapid sequences, etc.)
3. Explainability engine explains detected patterns
4. LLM generates 2-3 paragraph narrative in WHO/WHAT/WHEN/WHERE/WHY format
5. Save SAR with version tracking
6. Log audit entry
â†“
Response:
{
  "case_id": "CASE-a1b2c3d4",
  "sar_id": "SAR-x9y8z7u6",
  "sar_draft": "On 2024-02-14, customer John Doe (ID: C12345)...",
  "audit": {...},
  "explain": {"risk_score": 0.85, "patterns": ["bulk_transfer", "rapid_sequence"]}
}
```

#### **3. audit_routes.py** (20 lines)
```
Endpoints:   GET /audit/case/{case_id}  â€” Get audit trail for case

Logic:       â€¢ Query audit_logs table for all actions on case_id
             â€¢ Return filtered by user_id, action, timestamp
             â€¢ Include action details (what changed, by whom, when)

Example:
{
  "case_id": "CASE-a1b2c3d4",
  "audit_entries": [
    {
      "timestamp": "2026-02-16T10:30:00Z",
      "user_id": "analyst@bank.com",
      "action": "create_case",
      "details": {...}
    }
  ]
}
```

#### **4. auth_routes.py** (35 lines)
```
Endpoints:   POST /auth/login  â€” Authenticate user and return JWT

Logic:       â€¢ Accept username + password
             â€¢ Verify against hardcoded demo credentials:
               - admin / adminpass (role: admin)
               - analyst / password (role: analyst)
             â€¢ Generate JWT token valid for 24 hours
             â€¢ Include role in token payload for RBAC

Security:    â€¢ BCrypt password hashing
             â€¢ JWT signature with SECRET_KEY
             â€¢ Token contains: user_id, role, exp

Example:
POST /auth/login
{
  "username": "admin",
  "password": "adminpass"
}
â†“
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
  "token_type": "bearer",
  "user": {"user_id": "admin", "role": "admin"}
}
```

#### **5. risk_routes.py** (18 lines)
```
Endpoints:   POST /risk/analyze  â€” Analyze transactions for risk patterns

Logic:       â€¢ Accept transaction list
             â€¢ Detect patterns:
               - High-value transfers (>$50,000)
               - Rapid transaction sequences (>5 in 24h)
               - Destination country risk (high-risk jurisdictions)
               - Customer profile mismatch
             â€¢ Score risk (0.0 â€” 1.0)

Example Response:
{
  "risk_score": 0.78,
  "patterns": [
    {"name": "bulk_transfer", "confidence": 0.92},
    {"name": "high_velocity", "confidence": 0.65}
  ]
}
```

#### **6. rag_routes.py** (28 lines)
```
Endpoints:   POST /rag/reindex           â€” Rebuild FAISS index
             POST /rag/save              â€” Persist index to disk
             GET  /rag/load              â€” Load index from disk
             GET  /rag/query             â€” Query similar templates

Logic:       â€¢ Load SAR template library from sample_data/
             â€¢ Use sentence-transformers to create embeddings
             â€¢ Build FAISS index for semantic search
             â€¢ When generating SAR: query index for similar examples
             â€¢ Return top-3 matching templates

Example:
POST /rag/reindex
â†“
Embeds 50+ SAR templates using FAISS + sentence-transformers
â†“
{
  "status": "reindexed",
  "templates_count": 52,
  "indexed_dimensions": 384
}
```

#### **7. model_routes.py** (25 lines)
```
Endpoints:   GET /models/download  â€” Download LLM model
             GET /models/status    â€” Check model availability

Logic:       â€¢ RBAC: Only admins can download
             â€¢ Download community GGML quantized models
             â€¢ Verify file integrity
             â€¢ Return download link or cache local path

Supported Models:  mistral-7b.ggmlv3.q4_K_M
                   neural-chat-7b.ggmlv3.q4
```

---

### `backend/app/services/` â€” Business Logic

#### **1. storage.py** (120 lines)
```
Purpose:     SQLite database persistence layer

Functions:
  save_case(case_dict)           â†’ Insert case, return case_id
  get_case(case_id)              â†’ Fetch case with transactions
  save_sar(sar_id, case_id, narrative, audit) â†’ Insert SAR
  get_sar_by_id(sar_id)          â†’ Fetch SAR by ID
  get_sar_versions(case_id)      â†’ List all SAR versions for case
  save_audit(audit_id, case_id, user_id, action, details) â†’ Log action
  get_audit_trail(case_id)       â†’ Fetch all audit entries for case

Database Schema:
â”Œâ”€ cases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ case_id (PK)               â”‚
â”‚ customer_name              â”‚
â”‚ customer_id                â”‚
â”‚ alerts (JSON)              â”‚
â”‚ transactions (JSON)        â”‚
â”‚ created_at (timestamp)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ sars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sar_id (PK)                â”‚
â”‚ case_id (FK)               â”‚
â”‚ draft (narrative text)     â”‚
â”‚ version_id                 â”‚
â”‚ created_at                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ audit_logs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ audit_id (PK)              â”‚
â”‚ case_id (FK)               â”‚
â”‚ user_id                    â”‚
â”‚ action (create/modify)     â”‚
â”‚ details (JSON)             â”‚
â”‚ timestamp                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ sar_versions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ version_id (PK)            â”‚
â”‚ case_id (FK)               â”‚
â”‚ sar_id (FK)                â”‚
â”‚ draft (text)               â”‚
â”‚ created_at                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **2. sar_generator.py** (45 lines)
```
Purpose:     SAR narrative generation orchestration

Key Function:
  generate_sar_narrative(case, transactions, risk_summary, templates=None)
  â†’ Returns: (narrative_text, audit_dict)

Algorithm:
  1. Extract customer name, timestamp from case
  2. Query RAG store for similar SAR templates (semantic search)
  3. Build prompt: 
     - System instructions (neutral tone, who/what/when/where/why/how)
     - Case details + transactions + risk summary
     - Retrieved templates as examples
  4. Call LLM (stub/local/huggingface)
  5. Extract narrative from response
  6. Create audit entry with metadata:
     - Generated timestamp
     - Model name used
     - Data points (transaction count, template sources)

Output Format:
{
  "narrative": "On February 16, 2026, customer Jane Smith (ID: C99999) ...",
  "audit": {
    "generated_at": "2026-02-16T10:45:30Z",
    "model": "stub_model",
    "prompt_version": "v1",
    "data_points": {
      "tx_count": 8,
      "retrieved_templates": ["template_5", "template_12"]
    }
  }
}
```

#### **3. risk_engine.py** (60 lines)
```
Purpose:     Transaction pattern analysis for suspicious activity detection

Key Function:
  detect_patterns(transactions) â†’ risk_summary_dict

Patterns Detected:
  1. bulk_transfer_alert
     Condition: Single transaction > $50,000
     Score boost: +0.30

  2. high_velocity
     Condition: >5 transactions in 24 hours
     Score boost: +0.25

  3. destination_jurisdiction_risk
     Condition: Transaction to high-risk countries (N.Korea, Iran, Syria)
     Score boost: +0.40

  4. customer_profile_mismatch
     Condition: Transaction amount > customer's typical profile
     Score boost: +0.15

  5. round_amount_pattern
     Condition: Multiple round-number transactions (exact $5K, $10K, $50K)
     Score boost: +0.10

Output:
{
  "risk_score": 0.72,
  "patterns": [
    {"name": "bulk_transfer_alert", "confidence": 0.92, "details": "Transfer of $75,000"},
    {"name": "high_velocity", "confidence": 0.60, "details": "8 transactions in 12 hours"}
  ],
  "flagged_transactions": [123, 456],
  "recommendation": "Escalate for manual review"
}
```

#### **4. rag_store.py** (80 lines)
```
Purpose:     Semantic search using FAISS + sentence-transformers

Key Class:   RAGStore
Methods:
  index_templates(template_dir) â†’ Build vector index from files
  query(question, top_k=3)       â†’ Find similar SAR templates
  save_index(path)               â†’ Persist FAISS index to disk
  load_index(path)               â†’ Load pre-built index from disk

Technical:
  â€¢ Embedding Model: sentence-transformers/all-MiniLM-L6-v2 (384-dim)
  â€¢ Vector DB: FAISS (fast approximate nearest neighbor search)
  â€¢ Index Type: IVFFlat (inverted file, good for <1M documents)

Workflow:
  1. During app startup: Load embeddings for all SAR templates
  2. When generating SAR:
     - Convert query (case + transactions) to embedding
     - Find 3 most similar templates in index
     - Pass to LLM as context examples
  3. On shutdown: Save updated index to disk for persistence

Example:
rag_store.query("Bulk transfer to Middle East by retail customer")
â†“
Returns:
[
  {
    "text": "Customer transferred $100,000 to UAE bank account...",
    "source": "template_high_value_transfer.txt",
    "similarity_score": 0.89
  },
  {
    "text": "Rapid sequence of international transfers detected...",
    "source": "template_international_pattern.txt",
    "similarity_score": 0.76
  }
]
```

#### **5. llm.py** (70 lines)
```
Purpose:     LLM model interface with multiple backends

Supported Modes:
  â€¢ stub       : Returns mock responses (for testing)
  â€¢ local      : Runs llama-cpp-python with GGML model
  â€¢ huggingface: Calls HuggingFace Inference API

Key Function:
  generate(prompt, max_tokens=500, temperature=0.7) â†’ response_dict

Configuration (via environment variables):
  LLM_MODE              : "stub" | "local" | "huggingface"
  LLM_MODEL_PATH        : Path to .ggml file (for local mode)
  HUGGINGFACE_API_KEY   : API token (for huggingface mode)
  LLM_MODEL             : Model name (for huggingface mode)

Response Format:
{
  "text": "Generated narrative text...",
  "model": "mistral-7b.ggmlv3.q4_K_M",
  "tokens_used": 342,
  "completed": true
}

Stub Mode Response (for demo without LLM):
{
  "text": "On [DATE], customer [NAME] initiated a series of transfers totaling $[AMOUNT]...",
  "model": "stub_model",
  "tokens_used": 0,
  "completed": true
}
```

#### **6. explainability_engine.py** (55 lines)
```
Purpose:     Generate human-readable explanations for risk decisions

Key Function:
  explain_decision(risk_summary, transactions) â†’ explanation_dict

Output:
{
  "risk_score": 0.78,
  "decision_summary": "ESCALATE: High-risk patterns detected",
  "patterns_explained": [
    {
      "pattern": "bulk_transfer_alert",
      "explanation": "Customer transferred $75,000 in single transaction, exceeding typical profile",
      "confidence": 0.92,
      "recommendation": "Verify business purpose and source of funds"
    }
  ],
  "overall_recommendation": "Require additional customer documentation",
  "reasoning_trace": [
    "1. Detected bulk transfer: $75,000",
    "2. No prior large transfers in customer history",
    "3. Destination: High-risk jurisdiction",
    "4. Cumulative risk score: 0.78 (threshold: 0.70)",
    "5. Recommendation: Manual review required"
  ]
}
```

#### **7. audit_logger.py** (45 lines)
```
Purpose:     Comprehensive audit trail for compliance

Key Function:
  log_audit(user, case_id, user_id, action, details) â†’ audit_entry

Tracked Events:
  â€¢ create_case          : New case submission
  â€¢ generate_sar         : SAR narrative auto-generation
  â€¢ modify_narrative     : Manual narrative edits
  â€¢ export_pdf           : PDF export
  â€¢ add_comment          : Analyst comments
  â€¢ escalate_case        : Case escalation
  â€¢ close_case           : Case closure

Audit Entry Structure:
{
  "audit_id": "AUD-2026021610453001",
  "timestamp": "2026-02-16T10:45:30.001Z",
  "user_id": "analyst@bank.com",
  "action": "generate_sar",
  "case_id": "CASE-a1b2c3d4",
  "details": {
    "sar_id": "SAR-x9y8z7u6",
    "model_used": "stub_model",
    "risk_score": 0.78,
    "audit_metadata": {...}
  },
  "ip_address": "127.0.0.1",
  "user_agent": "Streamlit/1.28.0"
}

Query Examples:
  â€¢ All actions on CASE-123 by any user
  â€¢ All SAR generations in last 24 hours
  â€¢ All exports by analyst1
  â€¢ Complete change history for specific SAR
```

#### **8. rbac_service.py** (50 lines)
```
Purpose:     Role-based access control

Roles:
  admin      : Full access â€” can view all cases, generate SARs, export PDFs, manage users
  analyst    : Limited access â€” can view assigned cases, generate SARs, export PDFs
  viewer     : Read-only â€” can view published SARs only

Functions:
  check_permission(user_id, role, resource, action) â†’ bool
  has_role(user_id, required_role) â†’ bool
  get_user_cases(user_id) â†’ case_list

Permission Matrix:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Action         â”‚ Admin  â”‚ Analyst â”‚ Viewer â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Create Case    â”‚   âœ“    â”‚    âœ“    â”‚   âœ—    â”‚
â”‚ Generate SAR   â”‚   âœ“    â”‚    âœ“    â”‚   âœ—    â”‚
â”‚ Export PDF     â”‚   âœ“    â”‚    âœ“    â”‚   âœ—    â”‚
â”‚ View Audit     â”‚   âœ“    â”‚    âœ“    â”‚   âœ—    â”‚
â”‚ Modify SAR     â”‚   âœ“    â”‚    âœ“    â”‚   âœ—    â”‚
â”‚ View Report    â”‚   âœ“    â”‚    âœ“    â”‚   âœ“    â”‚
â”‚ Manage Users   â”‚   âœ“    â”‚    âœ—    â”‚   âœ—    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **9. exporter.py** (65 lines)
```
Purpose:     SAR export to PDF with professional formatting

Key Function:
  sar_to_pdf_bytes(narrative, case) â†’ pdf_binary_data

Features:
  â€¢ ReportLab for PDF generation
  â€¢ Professional header with bank logo space
  â€¢ Case metadata section (customer name, ID, date)
  â€¢ Narrative body with proper formatting
  â€¢ Transaction summary table
  â€¢ Risk analysis section
  â€¢ Footer with document metadata
  â€¢ Page numbers and timestamps

PDF Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SUSPICIOUS ACTIVITY REPORT       â”‚
â”‚                                         â”‚
â”‚  Case ID: CASE-a1b2c3d4                â”‚
â”‚  Customer: John Doe (ID: C12345)       â”‚
â”‚  Generated: 2026-02-16                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NARRATIVE                              â”‚
â”‚  On February 16, 2026, customer John    â”‚
â”‚  Doe initiated a series of transfers... â”‚
â”‚  [Body text continues]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€ Transaction Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Date       â”‚ Amount â”‚ Destination      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2026-02-14 â”‚ $50K   â”‚ UAE Bank Account â”‚
â”‚ 2026-02-14 â”‚ $25K   â”‚ Hong Kong        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **10. task_manager.py** (40 lines)
```
Purpose:     Async task management for long-running operations

Backend: Redis + RQ (Redis Queue)

Supported Tasks:
  â€¢ generate_sar_batch        : Bulk SAR generation
  â€¢ export_multiple_sars      : Multi-SAR PDF export
  â€¢ reindex_templates         : Rebuild RAG index
  â€¢ cleanup_old_versions      : Archive old SAR versions

Usage:
from services.task_manager import queue_task
task_id = queue_task("generate_sar_batch", case_ids=[...])
# Later: check_task_status(task_id)
```

#### **11. prompt_templates.py** (25 lines)
```
Purpose:     System prompts for LLM

SAR_SYSTEM_PROMPT:
"""You are a Suspicious Activity Report (SAR) analyst.
Your task is to generate a professional SAR narrative based on:
1. Customer information (who)
2. Transaction details (what, when, where)
3. Risk analysis (why this is suspicious)
4. Industry context and regulations

Format your response in clear paragraphs following WHO/WHAT/WHEN/WHERE/WHY/HOW structure.
Maintain neutral, factual tone. Include:
- Customer profile mismatch if present
- Transaction amount justification
- Geographic risk factors
- Reasoning for each pattern detected

Do NOT include personal opinions or judgments. Use standard SAR terminology."""
```

---

### `backend/app/database/` â€” Data Layer

#### **schema.sql** (80 lines)
```sql
-- Core tables for SAR system

CREATE TABLE IF NOT EXISTS cases (
  case_id TEXT PRIMARY KEY,
  customer_name TEXT NOT NULL,
  customer_id TEXT,
  alerts TEXT,  -- JSON array of alerts
  transactions TEXT,  -- JSON array of transactions
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS sars (
  sar_id TEXT PRIMARY KEY,
  case_id TEXT NOT NULL REFERENCES cases(case_id),
  draft TEXT,  -- SAR narrative
  version_id INTEGER DEFAULT 1,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS audit_logs (
  audit_id TEXT PRIMARY KEY,
  case_id TEXT REFERENCES cases(case_id),
  user_id TEXT,
  action TEXT,  -- create_case, generate_sar, export_pdf, etc.
  details TEXT,  -- JSON with action details
  timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS sar_versions (
  version_id INTEGER PRIMARY KEY AUTOINCREMENT,
  case_id TEXT NOT NULL REFERENCES cases(case_id),
  sar_id TEXT REFERENCES sars(sar_id),
  draft TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_cases_customer_id ON cases(customer_id);
CREATE INDEX idx_sars_case_id ON sars(case_id);
CREATE INDEX idx_audit_case_id ON audit_logs(case_id);
```

#### **db.py** (30 lines)
```python
Purpose:     SQLAlchemy database configuration

Key Elements:
  DATABASE_URL  : sqlite:///sar_ai.db (configurable via env)
  SessionLocal  : Database session factory
  Base          : SQLAlchemy declarative base
  get_db()      : Dependency injection for FastAPI routes
```

---

### `backend/app/utils/` â€” Helper Functions

#### **validators.py** (35 lines)
```python
Purpose:     Input validation for API payloads

Functions:
  validate_case_payload(payload) â†’ bool
    Checks: customer_name, customer_id, transactions array
  
  validate_transaction(tx) â†’ bool
    Checks: amount, date, destination, type
  
  validate_email(email) â†’ bool
    Standard email format validation
```

---

### Root Backend Files

#### **requirements.txt** (18 dependencies)
```
fastapi==0.104.1              # Web framework
uvicorn==0.24.0               # ASGI server
sqlalchemy==2.0.23            # ORM
sqlite3                       # Database (included)
jwt==1.3.0                    # JSON Web Tokens
passlib==1.7.4                # Password hashing
bcrypt==4.0.1                 # Bcrypt implementation
requests==2.31.0              # HTTP client
sentence-transformers==2.2.2  # Embeddings
faiss-cpu==1.8.0              # Vector search
llama-cpp-python==0.1.59      # Local LLM
python-multipart==0.0.6       # Form parsing
pandas==2.1.3                 # Data handling
reportlab==4.0.7              # PDF generation
python-dotenv==1.0.0          # .env loading
redis==5.0.0                  # Redis client
rq==1.14.0                    # Job queue
```

#### **init_db.py** (30 lines)
```python
Purpose:     One-time database initialization script

Usage:       python init_db.py (from backend directory)

Actions:
  1. Check if sar_ai.db exists
  2. Read schema.sql
  3. Execute all CREATE TABLE statements
  4. Create sample index for RAG
  5. Verify all tables created successfully
  6. Print status report
```

---

## ðŸŽ¨ Frontend (`frontend/streamlit_app.py`)

**Total:** 397 lines of Streamlit code

### Page Configuration
```python
st.set_page_config(
    page_title="SAR AI Platform",
    page_icon="ðŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)
```

### **5 Main Pages**

#### **1. Dashboard** (40 lines)
Shows system status, quick metrics, and getting started guide.
- Metrics: Status (Ready), API (Connected), Database (Initialized), Demo Users (2)
- Quick Start: 4-step workflow illustration
- Features overview card

#### **2. Create Case** (85 lines)
Load sample cases and submit to backend.
- Dropdown selector for 10+ sample JSON cases
- Display case info in card layout (Case ID, Customer Name, Customer ID)
- Render alerts as pandas DataFrame table
- Render transactions with currency formatting (â‚¹)
- "Create Case" button with loading spinner
- Success/error feedback

#### **3. Generate SAR** (145 lines)
AI-powered narrative generation with editing.
```
4 Tabs:
  ðŸ“„ Draft         â†’ Editable textarea, Save/Reset buttons
  ðŸ” Analysis      â†’ Risk indicators, explainability panel
  ðŸ“Š Audit Trail   â†’ Transaction timeline + audit log
  â¬‡ï¸ Export        â†’ PDF/JSON download buttons
```

#### **4. View Audit Trail** (50 lines)
Complete audit history viewer.
- Filter by case ID
- Display table: timestamp, user, action, details
- Expandable details panel

#### **5. Settings** (40 lines)
Admin panel for system configuration.
- API connection tester with status
- Demo credentials display (admin/analyst)
- Database status checker
- Feature checklist (all âœ“)

### Session State Management
```python
st.session_state.current_case  # Holds loaded case data
st.session_state.current_sar   # Holds generated SAR
st.session_state.sar_draft     # Holds edited narrative
```

### Custom CSS Styling
```css
.card             /* Styled info cards */
.success-box      /* Green success boxes */
.error-box        /* Red error boxes */
.info-box         /* Blue info boxes */
```

### Error Handling
- Try-catch for all API calls
- User-friendly error messages
- Loading spinners for async operations
- Session timeouts (24 hours)

---

## ðŸ“Š Sample Data (`sample_data/`)

Directory containing 10+ JSON files with realistic SAR test cases.

Example: `sample_data/case_bulk_transfer.json`
```json
{
  "case_id": "CASE-bulk-001",
  "customer_name": "John Doe",
  "customer_id": "C12345",
  "alerts": [
    {
      "alert_id": "ALT-001",
      "alert_type": "HIGH_AMOUNT_TRANSFER",
      "amount": 75000,
      "date": "2026-02-14"
    }
  ],
  "transactions": [
    {
      "tx_id": 1,
      "amount": 50000,
      "date": "2026-02-14",
      "type": "transfer",
      "destination": "UAE"
    },
    {
      "tx_id": 2,
      "amount": 25000,
      "date": "2026-02-14",
      "type": "transfer",
      "destination": "Hong Kong"
    }
  ]
}
```

---

## ðŸ” Security Features

### Authentication
- JWT tokens with 24-hour expiration
- Bcrypt password hashing (rounds=12)
- All endpoints require token validation (except /auth/login and /)

### Authorization (RBAC)
- Admin: Full access
- Analyst: Case management access
- Viewer: Read-only access

### Audit Trail
- Every action logged with timestamp
- User ID tracking
- IP address logging
- Change history with diffs

### Data Protection
- SQLite encryption option (future)
- PII masking in logs
- Secure token handling
- HTTPS enforcement (production)

---

## ðŸš€ Running the System

### Backend
```powershell
cd backend
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
python init_db.py                    # Initialize DB
python -m uvicorn app.main:app --host 0.0.0.0 --port 8001
```

### Frontend
```powershell
cd ..
streamlit run frontend/streamlit_app.py --server.port 8501
```

### Both Together
```powershell
# Terminal 1
cd backend && python -m uvicorn app.main:app --host 0.0.0.0 --port 8001

# Terminal 2
cd frontend && streamlit run streamlit_app.py --server.port 8501

# Browser
Open http://localhost:8501
```

---

## ðŸ“ˆ Data Flow Example

**Complete workflow: Case â†’ SAR Generation â†’ PDF Export**

```
1. USER CREATES CASE
   FrontendUI (Create Case)
   â†“
   POST /cases/create
   â†“
   Backend: case_routes â†’ validate â†’ storage.save_case()
   â†“
   SQLite: INSERT INTO cases
   â†“
   Response: {"case_id": "CASE-abc123"}

2. USER GENERATES SAR
   Frontend (Generate SAR)
   â†“
   POST /sars/generate?case_id=CASE-abc123
   â†“
   Backend: sar_routes
   â”œâ”€ storage.get_case()  [fetch case + transactions]
   â”œâ”€ risk_engine.detect_patterns() [find suspicious activity]
   â”œâ”€ rag_store.query()   [retrieve similar SAR templates]
   â”œâ”€ llm.generate()      [write narrative]
   â”œâ”€ explainability_engine.explain_decision() [explain why]
   â””â”€ audit_logger.log_audit() [log action]
   â†“
   Response: {
     "case_id": "CASE-abc123",
     "sar_id": "SAR-xyz789",
     "sar_draft": "On 2026-02-14...",
     "explain": {"risk_score": 0.78, "patterns": [...]}
   }

3. USER EXPORTS PDF
   Frontend (Generate SAR â†’ Export tab)
   â†“
   GET /sars/export/SAR-xyz789
   â†“
   Backend: sar_routes â†’ exporter.sar_to_pdf_bytes()
   â†“
   Response: PDF binary file
   â†“
   Browser: Download CASE-abc123_SAR.pdf

4. USER VIEWS AUDIT
   Frontend (Audit Trail page)
   â†“
   GET /audit/case/CASE-abc123
   â†“
   Backend: audit_routes â†’ storage.get_audit_trail()
   â†“
   Response: [
     {"timestamp": "...", "user_id": "analyst", "action": "create_case"},
     {"timestamp": "...", "user_id": "system", "action": "generate_sar"},
     {"timestamp": "...", "user_id": "analyst", "action": "export_pdf"}
   ]
```

---

## ðŸŽ¯ Key Features Summary

âœ… **Core Features**
- Case management (create, retrieve, list)
- AI-powered SAR narrative generation
- Risk pattern detection (5+ patterns)
- Complete audit trail (every action logged)
- PDF export with professional formatting
- SAR versioning with diff comparison

âœ… **Advanced Features**
- RAG (Retrieval Augmented Generation) with FAISS
- Semantic template search
- Explainability engine (explain decisions)
- Role-based access control (Admin/Analyst/Viewer)
- JWT authentication
- Bcrypt password hashing
- Async task management (RQ/Redis)
- Multiple LLM backends (stub/local/huggingface)

âœ… **UI/UX**
- Multi-page Streamlit dashboard
- Session state management
- Real-time loading feedback
- Card-based information layout
- Pandas DataFrames for tables
- Emoji-enhanced icons
- Custom CSS styling
- Error handling with user messages

âœ… **Production Ready**
- Docker Compose (Redis, Postgres)
- Environment variable management
- Database migrations (Alembic)
- GitHub Actions CI/CD
- Comprehensive logging
- Error handling & recovery

---

## ðŸ“ File Count & Statistics

```
Backend Routes:         7 files (200+ lines)
Backend Services:      11 files (600+ lines)
Backend Utils:          2 files (65 lines)
Database:               2 files (110 lines)
Frontend:               1 file (397 lines)
Config & Scripts:       4 files (150 lines)
Sample Data:           10+ JSON files (~1000 lines)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                35+ files (~2,500 lines of code)
```

---

This architecture enables a **scalable, auditable, and intelligent SAR generation platform** suitable for enterprise financial compliance workflows.
